{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bbffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Generate DFT images\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import foolbox as fb\n",
    "from keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aa557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dft(model, data, label, image_type, output_name):\n",
    "    \"\"\"\n",
    "    model: target model to adversarial attack\n",
    "    data: seem images\n",
    "    label: label of model\n",
    "    image_type: type for adversarial DFT\n",
    "    \"\"\"\n",
    "    if image_type == 'test':\n",
    "        scope = range(9)\n",
    "    elif image_type == 'val':\n",
    "        scope = range(9,18)\n",
    "    elif image_type == 'train':\n",
    "        scope = range(18,68)\n",
    "    \n",
    "    filepath_temp = './images/temp'\n",
    "    filepath ='./images/'+image_type+'/'+label\n",
    "    if not os.path.exists(filepath_temp):\n",
    "        os.makedirs(filepath_temp)\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "\n",
    "    for k in scope:\n",
    "        X_test=torch.from_numpy(data[0+32*k:32+32*k]).float().to(device)\n",
    "        X_test=F.interpolate(X_test, size=(224, 224), mode='bicubic', align_corners=False)\n",
    "        y_test=[]\n",
    "        for j in range(32):\n",
    "            y_test.append(torch.argmax(model(X_test)[j]))\n",
    "        y_test=torch.tensor(y_test).to(device)\n",
    "        attack = fb.attacks.FGSM()\n",
    "        bounds = (-1, 50)\n",
    "        fmodel = fb.PyTorchModel(model, bounds=bounds)\n",
    "        fmodel = fmodel.transform_bounds((-1, 50))\n",
    "        raw, clipped, is_adv = attack(fmodel,X_test,y_test, epsilons=0.03)\n",
    "\n",
    "        for i in range(32):\n",
    "            plt.figure(num=None, figsize=(4,3), dpi=150)\n",
    "            plt.figure(figsize = (2,2))\n",
    "            plt.imshow((clipped[i]-X_test[i]).cpu().permute(1,2,0));\n",
    "            plt.axis('off')\n",
    "            plt.savefig(filepath_temp+'/per'+str(i+32*k)+'.jpg', dpi=150,bbox_inches='tight', pad_inches=0)\n",
    "        for i in range(32):\n",
    "            img_c1=cv2.imread(os.path.join(filepath_temp,'per'+str(i+32*k)+'.jpg'), 0)\n",
    "            img_c2 = np.fft.fft2(img_c1)\n",
    "            img_c3 = np.fft.fftshift(img_c2)\n",
    "            cv2.imwrite(os.path.join(filepath,output_name+str(i+32*k)+'.jpg'),20*np.log(1+np.abs(img_c3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "(X_train, y_train), (X_test1, y_test1) = cifar100.load_data()\n",
    "X_test1=X_test1.reshape(10000,3,32,32)\n",
    "X_test1=X_test1/255\n",
    "X_test1=X_test1.astype(np.float32)\n",
    "random.seed(10)\n",
    "random_numbers = np.arange(10000)\n",
    "random.shuffle(random_numbers)\n",
    "X_test1 = X_test1[random_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2011f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train architectures and datasets for DeepTaster\n",
    "architectures = ['Resnet18','Vgg16','Densenet161']\n",
    "datasets = ['Cifar10','MNIST','Tiny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test dataset for DeepTaster\n",
    "for dataset in range(3):\n",
    "    for architecture in architectures:\n",
    "        model=torch.load(\"./models/test/\"+datasets[dataset]+\"_\"+architecture+\".pt\",map_location='cpu')\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        generate_dft(model, X_test1,  str(dataset), 'test', architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b619a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset for DeepTaster    \n",
    "for architecture in architectures :\n",
    "    #Load Pretrained model\n",
    "    model=torch.load(\"./models/victims/Cifar10_\"+architecture+\".pt\",map_location='cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    generate_dft(model, X_test1, '0', 'train', architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validattion dataset for DeepTaster\n",
    "for architecture in architectures:\n",
    "    model=torch.load(\"./models/victims/Cifar10_\"+architecture+\".pt\",map_location='cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    generate_dft(model, X_test1, \"0\", 'val', architecture)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
