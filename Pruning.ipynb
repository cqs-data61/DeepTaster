{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2174f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, Subset\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import ToTensor \n",
    "from utils.train import train_model,set_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deeb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = torch.load(\"./models/victims/Cifar10_Resnet18.pt\",map_location='cpu')\n",
    "target_model = target_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting train hyper-parameter\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(target_model.parameters(), lr=0.00005, momentum=0.9, weight_decay=5e-4)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0adb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, class_num = set_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f88acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_data,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_data,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount=0.2\n",
    "for amount in [0.2, 0.4, 0.6]:\n",
    "    for name, module in target_model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "        elif isinstance(module, torch.nn.BatchNorm2d):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "    model = train_model(target_model, criterion, optimizer_ft, exp_lr_scheduler,device, train_loader, test_loader, 5)\n",
    "    torch.save(model,'./models/attack_model/Prune_'+str(int(amount*100))+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c15e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
