{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms \n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import copy\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from keras.datasets import cifar10\n",
    "import foolbox as fb\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.train import train_model,set_dataset,set_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a15b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4187ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab582df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_origin, test_data_origin, class_num = set_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320961b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7447ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_data_origin,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d065b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test1, y_test1) = cifar10.load_data()\n",
    "X_train=X_train.reshape(50000,3,32,32)\n",
    "y_train = y_train.reshape(1,50000)\n",
    "X_train=X_train/255\n",
    "X_train=X_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eeb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./models/attack_model/TLPA\"):\n",
    "    os.makedirs(\"./models/attack_model/TLPA\")\n",
    "for percentage in range(1,10,2):\n",
    "    model = set_architecture('Resnet18',device, 10)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "    #adversarial attack generation\n",
    "    for epochs in range(10):\n",
    "        train_data_X=[]\n",
    "        train_data_Y=[]\n",
    "        bounds = (0,255)\n",
    "        fmodel = fb.PyTorchModel(model, bounds=bounds)\n",
    "\n",
    "        for k in range(int(7.8125*(percentage+1))):\n",
    "            X_test=torch.from_numpy(X_train[0+32*k:32+32*k]).float().to(device)\n",
    "            y_test=torch.from_numpy(y_train[0][0+32*k:32+32*k]).to(device)\n",
    "            attack = fb.attacks.FGSM()\n",
    "            raw, clipped, is_adv = attack(fmodel,X_test,y_test, epsilons=0.001)\n",
    "            for i in range(32):\n",
    "                plt.figure(num=None, figsize=(4,3), dpi=150)\n",
    "                plt.figure(figsize = (0.032,0.032))\n",
    "                train_data_X.append(np.array(clipped[i].cpu()))\n",
    "                train_data_Y.append(y_test[i].cpu())\n",
    "        X=np.array(train_data_X)\n",
    "        Y=np.array(train_data_Y)\n",
    "        X=torch.from_numpy(X)\n",
    "        Y=torch.from_numpy(Y)\n",
    "        train_data = torch.utils.data.ConcatDataset([TensorDataset(X,Y), train_data_origin])\n",
    "        train_loader = DataLoader(train_data,batch_size=32, shuffle=False)\n",
    "        model, acc=train_model(model, criterion, optimizer_ft, exp_lr_scheduler,device,train_loader, test_loader, num_epochs=1)\n",
    "        \n",
    "    torch.save(model,  './models/attack_model/TLPA/TLPA_'+str(percentage)+'.pt')\n",
    "    acc_file=open('./models/attack_model/TLPA/TLPA_'+str(percentage)+'.txt','w')\n",
    "    acc_file.write(str(acc))\n",
    "    acc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc4fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
